import os
import zipfile
import numpy as np
import torch
from scipy.interpolate import interp1d
from torch_geometric.utils import dense_to_sparse
from torch_geometric_temporal.signal import StaticGraphTemporalSignal
from random import randrange

class METRLADatasetLoader(object):
    """A traffic forecasting dataset based on Los Angeles
    Metropolitan traffic conditions. The dataset contains traffic
    readings collected from 207 loop detectors on highways in Los Angeles
    County in aggregated 5 minute intervals for 4 months between March 2012
    to June 2012.

    For further details on the version of the sensor network and
    discretization see: `"Diffusion Convolutional Recurrent Neural Network:
    Data-Driven Traffic Forecasting" <https://arxiv.org/abs/1707.01926>`_
    """

    def __init__(self, anomaly_duration ,raw_data_dir=os.path.join(os.getcwd(), "data")):
        super(METRLADatasetLoader, self).__init__()
        self.raw_data_dir = raw_data_dir
        self.anomaly_duration = anomaly_duration
        self._read_data()

    def _read_data(self):
        # Check if zip file is extracted, otherwise extract
        if not os.path.isfile(
            os.path.join(self.raw_data_dir, "adj_mat.npy")
        ) or not os.path.isfile(
            os.path.join(self.raw_data_dir, "node_values.npy")
        ):  # pragma: no cover
            with zipfile.ZipFile(
                os.path.join(self.raw_data_dir, "METR-LA.zip"), "r"
            ) as zip_fh:
                zip_fh.extractall(self.raw_data_dir)

        A = np.load(os.path.join(self.raw_data_dir, "adj_mat.npy"))
        X = np.load(os.path.join(self.raw_data_dir, "node_values.npy")).transpose(
            (1, 2, 0)
        )

        X = X.astype(np.float32)

        X = self._anomaly_injection(X)

        self._normalise_data(X, A)


    def _anomaly_injection(self, X):
        for sensor in range(len(X)):
            y = X[sensor][0]
            idx = np.nonzero(y)
            if len(idx[0]) != len(y):
                x = np.arange(len(y))
                LinearInterp = interp1d(x[idx], y[idx], fill_value='extrapolate')
                X[sensor][0] = LinearInterp(x)

        self.dataset_size = len(X[0][0])
        # self.dataset_size = 2000

        max_speed = []
        min_speed = []

        for sensor in range(len(X)):
            max_speed.append(max(X[sensor][0]))
            min_speed.append(min(X[sensor][0]))

        self.anomaly_count = 0

        for timestep in range(200, 2000, 200):  #Injecting anomalies for the first 2000 timestamps
            for current_timestep in range(timestep, timestep + self.anomaly_duration) :
                self.anomaly_count += 1
                for sensor in range(0, len(X)):
                    X[sensor][0][current_timestep] = self._get_anomaly(sensor, max_speed, min_speed)

        return X


    def _get_anomaly(self, sensor, max_speed, min_speed):
        if(randrange(0, 2)):
            return max_speed[sensor] + randrange(5, 11);
        else:
            return max(min_speed[sensor] - randrange(5, 11), 0)

    def _normalise_data(self, X, A):
        # Normalise as in DCRNN paper (via Z-Score Method)
        means = np.mean(X, axis=(0, 2))
        stds = np.std(X, axis=(0, 2))

        X = X - means.reshape(1, -1, 1)
        X = X / stds.reshape(1, -1, 1)

        self.A = torch.from_numpy(A)
        self.X = torch.from_numpy(X)

    def _get_edges_and_weights(self):
        edge_indices, values = dense_to_sparse(self.A)
        edge_indices = edge_indices.numpy()
        values = values.numpy()
        self.edges = edge_indices
        self.edge_weights = values

    def _generate_task(self, num_timesteps_in: int = 12, num_timesteps_out: int = 12):
        """Uses the node features of the graph and generates a feature/target
        relationship of the shape
        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)
        predicting the average traffic speed using num_timesteps_in to predict the
        traffic conditions in the next num_timesteps_out

        Args:
            num_timesteps_in (int): number of timesteps the sequence model sees
            num_timesteps_out (int): number of timesteps the sequence model has to predict
        """
        indices = [
            (i, i + (num_timesteps_in + num_timesteps_out))
            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)
        ]

        # Generate observations
        features, target = [], []
        for i, j in indices:
            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())
            target.append((self.X[:, :, i + num_timesteps_in : j]).numpy())

        self.features = features
        self.targets = target

    def get_dataset(
        self,num_timesteps_in: int = 12, num_timesteps_out: int = 12
    ) -> StaticGraphTemporalSignal:
        """Returns data iterator for METR-LA dataset as an instance of the
        static graph temporal signal class.

        Return types:
            * **dataset** *(StaticGraphTemporalSignal)* - The METR-LA traffic
                forecasting dataset.
        """
        self._get_edges_and_weights()
        self._generate_task(num_timesteps_in, num_timesteps_out)
        dataset = StaticGraphTemporalSignal(
            self.edges, self.edge_weights, self.features, self.targets
        )

        return dataset, self.anomaly_count, self.dataset_size

dataset, anomaly_count, dataset_size = METRLADatasetLoader(50).get_dataset()
